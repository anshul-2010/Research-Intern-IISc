{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472d4f40",
   "metadata": {},
   "source": [
    "Training Parameters to be worked on for accuracy\n",
    "\n",
    "1. the mean and the std values for the dataloader source and target could be tried varying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8279fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c2d07",
   "metadata": {},
   "source": [
    "### Gradient Reversal Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f4aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bdee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReverseLayer(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)*alpha\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg()*ctx.alpha\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150f1ee",
   "metadata": {},
   "source": [
    "### The three models: Feature Extractor, Class Classifier, Domain CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2161b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d7022aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential()\n",
    "        self.feature_extractor.add_module('conv1', nn.Conv2d(3, 64, kernel_size=5)),\n",
    "        self.feature_extractor.add_module('batchnorm1', nn.BatchNorm2d(64)),\n",
    "        self.feature_extractor.add_module('maxpool1', nn.MaxPool2d(2)),\n",
    "        self.feature_extractor.add_module('relu1', nn.ReLU(True)),\n",
    "        self.feature_extractor.add_module('conv2', nn.Conv2d(64, 50, kernel_size=5)),\n",
    "        self.feature_extractor.add_module('batchnorm2', nn.BatchNorm2d(50)),\n",
    "        self.feature_extractor.add_module('drop1', nn.Dropout2d())\n",
    "        self.feature_extractor.add_module('maxpool2', nn.MaxPool2d(2)),\n",
    "        self.feature_extractor.add_module('relu2', nn.ReLU(True))\n",
    "        \n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('fc1', nn.Linear(50*4*4, 100)),\n",
    "        self.class_classifier.add_module('batchnorm1', nn.BatchNorm1d(100)),\n",
    "        self.class_classifier.add_module('relu1', nn.ReLU(True)),\n",
    "        self.class_classifier.add_module('drop1', nn.Dropout2d()),\n",
    "        self.class_classifier.add_module('fc2', nn.Linear(100, 100)),\n",
    "        self.class_classifier.add_module('batchnorm2', nn.BatchNorm1d(100)),\n",
    "        self.class_classifier.add_module('relu2', nn.ReLU(True)),\n",
    "        self.class_classifier.add_module('fc3', nn.Linear(100, 10)),\n",
    "        self.class_classifier.add_module('softmax', nn.LogSoftmax()),\n",
    "        \n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('fc1', nn.Linear(50*4*4, 100)),\n",
    "        self.domain_classifier.add_module('batchnorm1', nn.BatchNorm1d(100)),\n",
    "        self.domain_classifier.add_module('relu1', nn.ReLU(True)),\n",
    "        self.domain_classifier.add_module('fc2', nn.Linear(100, 2)),\n",
    "        self.domain_classifier.add_module('softmax', nn.LogSoftmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        alpha=0.5\n",
    "        x = x.expand(x.data.shape[0], 3, 28, 28)\n",
    "        feature = self.feature_extractor(x)\n",
    "        feature = feature.view(-1, 50*4*4)\n",
    "        reverse = GradientReverseLayer(feature, alpha)\n",
    "        class_output = self.class_classifier(feature)\n",
    "        domain_ouput = self.domain_classifier(reverse)\n",
    "        return class_output, domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a5df91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not GradientReverseLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DANN()\n\u001b[1;32m----> 2\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[11], line 40\u001b[0m, in \u001b[0;36mDANN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m reverse \u001b[38;5;241m=\u001b[39m GradientReverseLayer(feature, alpha)\n\u001b[0;32m     39\u001b[0m class_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_classifier(feature)\n\u001b[1;32m---> 40\u001b[0m domain_ouput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m class_output, domain_output\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1543\u001b[0m     ):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not GradientReverseLayer"
     ]
    }
   ],
   "source": [
    "model = DANN()\n",
    "summary(model,(3,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a280ab60",
   "metadata": {},
   "source": [
    "#### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da3977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14d1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_image(x):\n",
    "    return x.repeat(3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e32d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.31842041015625 \n",
      "Pixel Values Std: 78.56748962402344\n",
      "Scaled Mean Pixel Value 0.13066047430038452 \n",
      "Scaled Pixel Values Std: 0.30810779333114624\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST        \n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "trainset_bla = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(trainset_bla.data.min(), trainset_bla.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(trainset_bla.data.float().mean(), trainset_bla.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(trainset_bla.data.float().mean() / 255, trainset_bla.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f7e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "lr = 1e-3\n",
    "image_size = 28\n",
    "\n",
    "\n",
    "img_transform_source = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = (0.1307,), std = (0.3081,))\n",
    "])\n",
    "img_transform_target = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9eed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                       ])),\n",
    "        batch_size=128, shuffle=True,num_workers=1)\n",
    "source_test = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                       ])),\n",
    "        batch_size=128, shuffle=False,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26866f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLoader(data.Dataset):\n",
    "    def __init__(self, data_root, data_list, transform=None):\n",
    "        self.root = data_root\n",
    "        self.transform = transform\n",
    "\n",
    "        f = open(data_list, 'r')\n",
    "        data_list = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        self.n_data = len(data_list)\n",
    "\n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "\n",
    "        for data in data_list:\n",
    "            self.img_paths.append(data[:-3])\n",
    "            self.img_labels.append(data[-2])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_paths, labels = self.img_paths[item], self.img_labels[item]\n",
    "        imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            imgs = self.transform(imgs)\n",
    "            labels = int(labels)\n",
    "\n",
    "        return imgs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f5d1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=28\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "])\n",
    "train_list = 'C:\\\\Users\\\\Dell\\\\Downloads\\\\mnist_m\\\\mnist_m\\\\mnist_m_train_labels.txt'\n",
    "dataset_train_target = GetLoader(\n",
    "    data_root='C:\\\\Users\\\\Dell\\\\Downloads\\\\mnist_m\\\\mnist_m\\\\mnist_m_train',\n",
    "    data_list=train_list,\n",
    "    transform=img_transform\n",
    ")\n",
    "test_list = 'C:\\\\Users\\\\Dell\\\\Downloads\\\\mnist_m\\\\mnist_m\\\\mnist_m_test_labels.txt'\n",
    "dataset_test_target = GetLoader(\n",
    "    data_root='C:\\\\Users\\\\Dell\\\\Downloads\\\\mnist_m\\\\mnist_m\\\\mnist_m_test',\n",
    "    data_list=test_list,\n",
    "    transform=img_transform\n",
    ")\n",
    "target_train = torch.utils.data.DataLoader(dataset_train_target,batch_size=128, shuffle=True,num_workers=1)\n",
    "target_test = torch.utils.data.DataLoader(dataset_test_target,batch_size=128, shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1bba99",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dabe260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e09b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DANN()\n",
    "optimizer = optim.SGD(model.parameters(), lr= lr, momentum= 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def optimizer_scheduler(optimizer, p):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
    "    return optimizer\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54134290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in source_test:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, _ = model(data,0.5)\n",
    "            test_loss += float(criterion(output, target))  # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += float(pred.eq(target.view_as(pred)).sum())\n",
    "\n",
    "    test_loss /= len(source_test.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(source_test.dataset),\n",
    "        100. * correct / len(source_test.dataset)))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in target_train:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, _ = model(data,0.5)\n",
    "            test_loss += float(criterion(output, target))  # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += float(pred.eq(target.view_as(pred)).sum())\n",
    "\n",
    "    test_loss /= len(target_train.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(target_train.dataset),\n",
    "        100. * correct / len(target_train.dataset)))\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in target_test:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, _ = model(data,0.5)\n",
    "            test_loss += float(criterion(output, target))  # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += float(pred.eq(target.view_as(pred)).sum())\n",
    "\n",
    "    test_loss /= len(target_test.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(target_test.dataset),\n",
    "        100. * correct / len(target_test.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ca419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461 469\n"
     ]
    }
   ],
   "source": [
    "print(len(target_train),len(source_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e74b22",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allepoch=100\n",
    "\n",
    "for epoch in range(allepoch):\n",
    "    len_dataloader = min(len(source_train), len(target_train))\n",
    "    total_steps = allepoch * len(source_train)\n",
    "    i = 0\n",
    "    for batch_idx, (data_source, data_target) in enumerate(zip(source_train, target_train)):\n",
    "        print(batch_idx, epoch)\n",
    "        start_time = time.time()\n",
    "        s_img, s_label = data_source\n",
    "        print(\"***\", s_label)\n",
    "\n",
    "        start_steps = epoch * len(source_train)\n",
    "\n",
    "        p = float(i + start_steps) / total_steps\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        optimizer = optimizer_scheduler(optimizer, p)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        domain_label = torch.zeros(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "\n",
    "        \n",
    "        a,b = model(s_img,alpha)\n",
    "        err_s_label = criterion(a, s_label)\n",
    "        err_s_domain = criterion(b, domain_label)\n",
    "\n",
    "        # training model using target data\n",
    "        t_img, _ = data_target\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "\n",
    "        domain_label = torch.ones(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "\n",
    "\n",
    "\n",
    "        _, b = model(t_img,alpha)\n",
    "        err_t_domain = criterion(b, domain_label)\n",
    "        err = err_s_label + err_s_domain + err_t_domain\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if(i % 1000 == 0):\n",
    "            print('epoch:{},[{}/{}],s_label:{:.3f},s_domain:{:.3f},t_domain:{:.3f},time{}'.\n",
    "                      format(epoch, i, len_dataloader, float(err_s_label), float(err_s_domain),\n",
    "                             float(err_t_domain), time.time() - start_time))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab0cc9",
   "metadata": {},
   "source": [
    "### alternate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3088cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = DANN()\n",
    "\n",
    "# setup optimizer\n",
    "n_epoch = 100\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "image_size = 28\n",
    "cuda = True\n",
    "cudnn.benchmark = True\n",
    "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "for p in my_net.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(source_train), len(target_train))\n",
    "    data_source_iter = iter(source_train)\n",
    "    data_target_iter = iter(target_train)\n",
    "    \n",
    "    print(\"Hi\", epoch)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len_dataloader:\n",
    "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        \n",
    "        # training model using source data\n",
    "        data_source = data_source_iter.next()\n",
    "        s_img, s_label = data_source\n",
    "        \n",
    "        print(s_label, \"**\")\n",
    "        my_net.zero_grad()\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "        class_label = torch.LongTensor(batch_size)\n",
    "        domain_label = torch.zeros(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "        \n",
    "        input_img.resize_as_(s_img).copy_(s_img)\n",
    "        class_label.resize_as_(s_label).copy_(s_label)\n",
    "        \n",
    "        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
    "        err_s_label = loss_class(class_output, class_label)\n",
    "        err_s_domain = loss_domain(domain_output, domain_label)\n",
    "        \n",
    "        # training model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, _ = data_target\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "        \n",
    "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "        domain_label = torch.ones(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "        \n",
    "        input_img.resize_as_(t_img).copy_(t_img)\n",
    "\n",
    "        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
    "        err_t_domain = loss_domain(domain_output, domain_label)\n",
    "        err = err_t_domain + err_s_domain + err_s_label\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i, len_dataloader, err_s_label.cpu().data.numpy(),\n",
    "                 err_s_domain.cpu().data.numpy(), err_t_domain.cpu().data.numpy()))\n",
    "\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8f6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
